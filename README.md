# Movies-ETL
Creating an Algorithm To Predict Successful Streaming Content 

ETL Extract transform and load
A core concept to unsure the data is consistent and maintains its integrity
Data stores more efficiency. Using ETL to create data pipelines and transform the data so that we can analyze. 

Extract
Trnsform
Load

I gathered data from both Wikipedia and Kaggle, combined them, and saved them into a SQL database. To do this I followed the ETL process: 
1)Extracting the Wikipedia and Kaggle data from their respective files. 
2)Transforming the datasets by cleaning them up and joining them together. 
3)Loading the cleaned dataset into a SQL database.

(Raw data exists in multiple places and needs to be cleaned and structured before it can be analyzed. ETL breaks this problem into three steps, or phases: Extract, Transform, and Load.)

